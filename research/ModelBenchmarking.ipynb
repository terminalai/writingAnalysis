{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Benchmarking Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick model names based on https://huggingface.co/models. Then just run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"data/feedback_prize/train.csv\"\n",
    "batch_size = 2\n",
    "epochs = 5\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "# model_checkpoints = [\"distilbert-base-uncased\", \"bert-base-uncased\", \"roberta-base\", \"distilgpt2\"]\n",
    "model_checkpoints = [\"distilgpt2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from datasets import load_metric\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up gpu device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423A1CA112E2</th>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423A1CA112E2</th>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423A1CA112E2</th>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423A1CA112E2</th>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423A1CA112E2</th>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4C471936CD75</th>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>if I'm not sure what college I want to attend...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>386 387 388 389 390 391 392 393 394 395 396 39...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4C471936CD75</th>\n",
       "      <td>1.618153e+12</td>\n",
       "      <td>3221.0</td>\n",
       "      <td>4509.0</td>\n",
       "      <td>seeking multiple opinions before making a har...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>576 577 578 579 580 581 582 583 584 585 586 58...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4C471936CD75</th>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4510.0</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>it is better to seekÂ multiple opinions instea...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>828 829 830 831 832 833 834 835 836 837 838</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4C471936CD75</th>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4570.0</td>\n",
       "      <td>4922.0</td>\n",
       "      <td>The impact of asking people to helpÂ you make ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>839 840 841 842 843 844 845 846 847 848 849 85...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4C471936CD75</th>\n",
       "      <td>1.618025e+12</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>5825.0</td>\n",
       "      <td>there are many other reasons one might want to...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>905 906 907 908 909 910 911 912 913 914 915 91...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144293 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              discourse_id  discourse_start  discourse_end  \\\n",
       "id                                                           \n",
       "423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "...                    ...              ...            ...   \n",
       "4C471936CD75  1.618153e+12           2234.0         3203.0   \n",
       "4C471936CD75  1.618153e+12           3221.0         4509.0   \n",
       "4C471936CD75  1.618025e+12           4510.0         4570.0   \n",
       "4C471936CD75  1.618025e+12           4570.0         4922.0   \n",
       "4C471936CD75  1.618025e+12           4935.0         5825.0   \n",
       "\n",
       "                                                           text  \\\n",
       "id                                                                \n",
       "423A1CA112E2  Modern humans today are always on their phone....   \n",
       "423A1CA112E2  They are some really bad consequences when stu...   \n",
       "423A1CA112E2  Some certain areas in the United States ban ph...   \n",
       "423A1CA112E2  When people have phones, they know about certa...   \n",
       "423A1CA112E2  Driving is one of the way how to get around. P...   \n",
       "...                                                         ...   \n",
       "4C471936CD75   if I'm not sure what college I want to attend...   \n",
       "4C471936CD75   seeking multiple opinions before making a har...   \n",
       "4C471936CD75  it is better to seekÂ multiple opinions instea...   \n",
       "4C471936CD75  The impact of asking people to helpÂ you make ...   \n",
       "4C471936CD75  there are many other reasons one might want to...   \n",
       "\n",
       "                    discourse_type      discourse_type_num  \\\n",
       "id                                                           \n",
       "423A1CA112E2                  Lead                  Lead 1   \n",
       "423A1CA112E2              Position              Position 1   \n",
       "423A1CA112E2              Evidence              Evidence 1   \n",
       "423A1CA112E2              Evidence              Evidence 2   \n",
       "423A1CA112E2                 Claim                 Claim 1   \n",
       "...                            ...                     ...   \n",
       "4C471936CD75              Evidence              Evidence 2   \n",
       "4C471936CD75              Evidence              Evidence 3   \n",
       "4C471936CD75              Position              Position 1   \n",
       "4C471936CD75              Evidence              Evidence 4   \n",
       "4C471936CD75  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                               predictionstring  label  \n",
       "id                                                                      \n",
       "423A1CA112E2  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...      4  \n",
       "423A1CA112E2       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59      5  \n",
       "423A1CA112E2    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75      3  \n",
       "423A1CA112E2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...      3  \n",
       "423A1CA112E2  139 140 141 142 143 144 145 146 147 148 149 15...      0  \n",
       "...                                                         ...    ...  \n",
       "4C471936CD75  386 387 388 389 390 391 392 393 394 395 396 39...      3  \n",
       "4C471936CD75  576 577 578 579 580 581 582 583 584 585 586 58...      3  \n",
       "4C471936CD75        828 829 830 831 832 833 834 835 836 837 838      5  \n",
       "4C471936CD75  839 840 841 842 843 844 845 846 847 848 849 85...      3  \n",
       "4C471936CD75  905 906 907 908 909 910 911 912 913 914 915 91...      1  \n",
       "\n",
       "[144293 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path, header=0, encoding= 'unicode_escape')\n",
    "\n",
    "df = df.set_index(\"id\")\n",
    "df = df.rename(columns={\"discourse_text\": \"text\"})\n",
    "\n",
    "df[\"discourse_type\"] = pd.Categorical(df[\"discourse_type\"])\n",
    "df[\"label\"] = df[\"discourse_type\"].cat.codes\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Claim',\n",
       " 1: 'Concluding Statement',\n",
       " 2: 'Counterclaim',\n",
       " 3: 'Evidence',\n",
       " 4: 'Lead',\n",
       " 5: 'Position',\n",
       " 6: 'Rebuttal'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define category_codes to use for labelling in the model id2label field\n",
    "category_codes = dict(zip(range(df[\"discourse_type\"].cat.categories.size),df[\"discourse_type\"].cat.categories))\n",
    "category_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'id'],\n",
       "        num_rows: 101005\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'id'],\n",
       "        num_rows: 28873\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label', 'id'],\n",
       "        num_rows: 14415\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df[[\"text\", \"label\"]])\n",
    "\n",
    "train_test_dataset = dataset.train_test_split(test_size=0.3)\n",
    "test_validation_dataset = train_test_dataset[\"test\"].train_test_split(test_size=0.333)\n",
    "\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    'train': train_test_dataset['train'],\n",
    "    'test': test_validation_dataset['train'],\n",
    "    'valid': test_validation_dataset['test']})\n",
    "\n",
    "train_test_valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream Retraining Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric_acc = load_metric(\"accuracy\")\n",
    "    metric_prec = load_metric(\"precision\")\n",
    "    metric_recall = load_metric(\"recall\")\n",
    "    metric_f1 = load_metric(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    acc = metric_acc.compute(predictions=predictions, references=labels)\n",
    "    prec = metric_prec.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    recall = metric_recall.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    f1 = metric_f1.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    kappa = cohen_kappa_score(predictions, labels)\n",
    "\n",
    "    return {\"accuracy\": acc['accuracy'], \"precision\": prec['precision'],\n",
    "            \"recall\": recall['recall'], \"f1\": f1['f1'], \"kappa\": kappa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd295d2048c461c83491b0da192a5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754632af89034e2bb31aa332b465fd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba44b3331b24716b9db62435e6f2796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: id, text.\n",
      "/home/weipyn/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 101005\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 252515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252515' max='252515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252515/252515 2:26:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.014300</td>\n",
       "      <td>1.013975</td>\n",
       "      <td>0.775153</td>\n",
       "      <td>0.773902</td>\n",
       "      <td>0.775153</td>\n",
       "      <td>0.770148</td>\n",
       "      <td>0.694934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.923200</td>\n",
       "      <td>1.067294</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.786434</td>\n",
       "      <td>0.787275</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.713879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.748500</td>\n",
       "      <td>1.147496</td>\n",
       "      <td>0.787518</td>\n",
       "      <td>0.786181</td>\n",
       "      <td>0.787518</td>\n",
       "      <td>0.786001</td>\n",
       "      <td>0.715873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.777100</td>\n",
       "      <td>1.211989</td>\n",
       "      <td>0.786894</td>\n",
       "      <td>0.786136</td>\n",
       "      <td>0.786894</td>\n",
       "      <td>0.785319</td>\n",
       "      <td>0.715444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>1.286081</td>\n",
       "      <td>0.786790</td>\n",
       "      <td>0.786927</td>\n",
       "      <td>0.786790</td>\n",
       "      <td>0.785826</td>\n",
       "      <td>0.715671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 28873\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-50503\n",
      "Configuration saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-50503/config.json\n",
      "Model weights saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-50503/pytorch_model.bin\n",
      "tokenizer config file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-50503/tokenizer_config.json\n",
      "Special tokens file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-50503/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 28873\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-101006\n",
      "Configuration saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-101006/config.json\n",
      "Model weights saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-101006/pytorch_model.bin\n",
      "tokenizer config file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-101006/tokenizer_config.json\n",
      "Special tokens file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-101006/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 28873\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-151509\n",
      "Configuration saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-151509/config.json\n",
      "Model weights saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-151509/pytorch_model.bin\n",
      "tokenizer config file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-151509/tokenizer_config.json\n",
      "Special tokens file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-151509/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 28873\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-202012\n",
      "Configuration saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-202012/config.json\n",
      "Model weights saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-202012/pytorch_model.bin\n",
      "tokenizer config file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-202012/tokenizer_config.json\n",
      "Special tokens file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-202012/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2ForSequenceClassification.forward` and have been ignored: id, text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 28873\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-252515\n",
      "Configuration saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-252515/config.json\n",
      "Model weights saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-252515/pytorch_model.bin\n",
      "tokenizer config file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-252515/tokenizer_config.json\n",
      "Special tokens file saved in models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-252515/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from models_gitignored/distilgpt2-finetuned-sentence-classification/checkpoint-50503 (score: 1.013974905014038).\n"
     ]
    }
   ],
   "source": [
    "for model_checkpoint in model_checkpoints:\n",
    "    # instantiate a model and assign it to a gpu/cpu device\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, \n",
    "                                                               num_labels=len(category_codes)).to(device)\n",
    "    # instantiate tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "        \n",
    "    def preprocess_function(examples):        \n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=False)\n",
    "    \n",
    "    # encode dataset using tokenizer\n",
    "    encoded_dataset = train_test_valid_dataset.map(preprocess_function, batched=True)\n",
    "    columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
    "    encoded_dataset.set_format(type='torch', columns=columns_to_return)\n",
    "    \n",
    "    \n",
    "    # training arguments\n",
    "    model_name = model_checkpoint.split(\"/\")[-1]\n",
    "    args = TrainingArguments(\n",
    "        f\"models_gitignored/{model_name}-finetuned-sentence-classification\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir = f'logs/{model_name}-finetuned-sentence-classification/save_metrics' # save directory for save_metrics() files\n",
    "    )\n",
    "\n",
    "    # trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=encoded_dataset[\"train\"],\n",
    "        eval_dataset=encoded_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # begin training\n",
    "    torch.cuda.empty_cache()\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    # log train results (2 different ways just in case)\n",
    "    metrics = train_result.metrics\n",
    "    trainer.save_metrics(\"all\", metrics)\n",
    "    \n",
    "    with open(f\"logs/{model_name}-finetuned-sentence-classification/log_history.txt\", \"w\") as fout:\n",
    "        for obj in trainer.state.log_history:\n",
    "            print(obj, file=fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
